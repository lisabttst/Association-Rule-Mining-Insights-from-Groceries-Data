{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eejkOZeqFIZz"
      },
      "source": [
        "# Travaux Pratiques\n",
        "\n",
        "\n",
        "\n",
        "Data Science - Règles d’Association\n",
        "décembre 2023\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR7d_II-D8xt"
      },
      "source": [
        "## **1. Chargez les données Groceries.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"arules\")\n"
      ],
      "metadata": {
        "id": "RgQlimqMyj5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44963350-a889-4159-affb-be958a5237a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjeqJJZIIksZ"
      },
      "source": [
        "(a) Appliquez l’algorithme apriori pour extraire des règles d’association"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6lP2vO8InVm"
      },
      "source": [
        "i. extrayez toutes les RA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4K1BLvhI0EQ",
        "outputId": "38c44307-8b4e-45a7-c81b-4fb53d07be52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: Matrix\n",
            "\n",
            "\n",
            "Attaching package: ‘arules’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    abbreviate, write\n",
            "\n",
            "\n",
            "Warning message in asMethod(object):\n",
            "“removing duplicated items in transactions”\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "        0.1    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen target  ext\n",
            "     10  rules TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[5729 item(s), 7501 transaction(s)] done [0.01s].\n",
            "sorting and recoding items ... [45 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "writing ... [19 rule(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "     lhs          rhs       support    confidence coverage   lift      count\n",
            "[1]  {}        => {tea}     0.10705239 0.1070524  1.00000000  1.000000 803  \n",
            "[2]  {rice}    => {wheat}   0.01226503 0.9583333  0.01279829 11.144897  92  \n",
            "[3]  {wheat}   => {rice}    0.01226503 0.1426357  0.08598853 11.144897  92  \n",
            "[4]  {sauce}   => {cream}   0.01026530 0.7938144  0.01293161 37.926128  77  \n",
            "[5]  {cream}   => {sauce}   0.01026530 0.4904459  0.02093054 37.926128  77  \n",
            "[6]  {water}   => {mineral} 0.01239835 0.5081967  0.02439675  6.606557  93  \n",
            "[7]  {mineral} => {water}   0.01239835 0.1611785  0.07692308  6.606557  93  \n",
            "[8]  {green}   => {tea}     0.01186508 0.5779221  0.02053060  5.398498  89  \n",
            "[9]  {tea}     => {green}   0.01186508 0.1108344  0.10705239  5.398498  89  \n",
            "[10] {french}  => {fries}   0.01786428 0.5114504  0.03492868  8.110760 134  \n",
            "[11] {fries}   => {french}  0.01786428 0.2832981  0.06305826  8.110760 134  \n",
            "[12] {whole}   => {wheat}   0.01893081 0.9466667  0.01999733 11.009220 142  \n",
            "[13] {wheat}   => {whole}   0.01893081 0.2201550  0.08598853 11.009220 142  \n",
            "[14] {herb}    => {&}       0.03092921 1.0000000  0.03092921 20.218329 232  \n",
            "[15] {&}       => {herb}    0.03092921 0.6253369  0.04946007 20.218329 232  \n",
            "[16] {yogurt}  => {fat}     0.06839088 0.9447514  0.07239035 12.345958 513  \n",
            "[17] {fat}     => {yogurt}  0.06839088 0.8937282  0.07652313 12.345958 513  \n",
            "[18] {tea}     => {wheat}   0.01173177 0.1095890  0.10705239  1.274461  88  \n",
            "[19] {wheat}   => {tea}     0.01173177 0.1364341  0.08598853  1.274461  88  \n"
          ]
        }
      ],
      "source": [
        "library(arules)\n",
        "\n",
        "# Lire les données (s'assurer que le chemin du fichier est correct)\n",
        "transactions <- read.transactions('store_data.csv', format = 'basket')\n",
        "\n",
        "# Application de l'algorithme Apriori\n",
        "rules <- apriori(transactions, parameter = list(supp = 0.01, conf = 0.1))\n",
        "\n",
        "# Afficher les règles\n",
        "inspect(rules)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interprétation des Résultats:**\n",
        "\n",
        "Support: Le support d'une règle indique la fréquence à laquelle les items de la règle apparaissent ensemble dans l'ensemble de données. Par exemple, la règle {tea} => {green} a un support de 0.01186508, ce qui signifie que 'tea' et 'green' apparaissent ensemble dans environ 1.19% de toutes les transactions.\n",
        "Confiance: La confiance mesure la fiabilité de l'inférence faite par une règle. Par exemple, la règle {sauce} => {cream} a une confiance de 0.7938144, ce qui signifie que dans 79.38% des cas où 'sauce' est achetée, 'cream' l'est aussi.\n",
        "Lift: Le lift mesure à quel point la présence d'un item (antécédent) augmente la probabilité de voir l'autre item (conséquent). Un lift supérieur à 1 indique une association positive. Par exemple, la règle {herb} => {&} a un lift de 20.218329, ce qui est significativement élevé, indiquant une forte association entre ces deux items.\n",
        "\n",
        "**Observations Notables:**\n",
        "Plusieurs règles ont un lift très élevé, comme {herb} => {&} et {sauce} => {cream}, ce qui suggère des associations très fortes.\n",
        "Certaines règles, comme {rice} => {wheat} et {whole} => {wheat}, ont à la fois une confiance et un lift élevés, indiquant qu'elles sont à la fois fiables et significatives.\n",
        "\n",
        "**Conclusion:**\n",
        "Ces règles d'association peuvent être utiles pour comprendre les comportements d'achat et pour les stratégies de marketing croisé. Par exemple, si un client achète 'sauce', il est très probable qu'il achète aussi 'cream'.\n",
        "Cependant, il est important de tenir compte de la couverture (fréquence relative des antécédents) pour s'assurer que les règles sont applicables à un nombre suffisant de cas."
      ],
      "metadata": {
        "id": "02iK7-kS0PDk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7HRtvkdIw-f"
      },
      "source": [
        "ii. imposez selon votre fantaisie une partie droite, puis une partie gauche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wDFfh4KdD0uE",
        "outputId": "b9d155f3-f6bd-4681-de2a-938667570210"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Imposer une partie droite (consequents) avec l'item 'milk'\n",
        "rules_with_milk <- subset(rules, rhs %in% \"milk\")\n",
        "\n",
        "# Imposer une partie gauche (antecedents) avec l'item 'bread'\n",
        "rules_with_bread <- subset(rules, lhs %in% \"bread\")\n",
        "\n",
        "# Afficher les règles\n",
        "inspect(rules_with_milk)\n",
        "inspect(rules_with_bread)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tROYJ3spI1FZ"
      },
      "source": [
        "(b) Appliquez l’algorithme apriori pour extraire des itemsets fréquents et maximaux."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfzebnizKjOj",
        "outputId": "715d26d4-ab5d-4b2c-deaa-6dbdebb146ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "         NA    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen            target  ext\n",
            "     10 frequent itemsets TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[5729 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [45 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "sorting transactions ... done [0.00s].\n",
            "writing ... [54 set(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "     items                    support    count\n",
            "[1]  {eggs}                   0.01199840  90  \n",
            "[2]  {escalope}               0.01346487 101  \n",
            "[3]  {chocolate}              0.01359819 102  \n",
            "[4]  {energy}                 0.01133182  85  \n",
            "[5]  {cookies}                0.02972937 223  \n",
            "[6]  {shrimp,frozen}          0.01026530  77  \n",
            "[7]  {rice}                   0.01279829  96  \n",
            "[8]  {dogs}                   0.01373150 103  \n",
            "[9]  {sauce}                  0.01293161  97  \n",
            "[10] {spaghetti,mineral}      0.01333156 100  \n",
            "[11] {wine}                   0.01573124 118  \n",
            "[12] {cake}                   0.02079723 156  \n",
            "[13] {cheese}                 0.01773097 133  \n",
            "[14] {drink}                  0.01799760 135  \n",
            "[15] {water}                  0.02439675 183  \n",
            "[16] {green}                  0.02053060 154  \n",
            "[17] {oil}                    0.02013065 151  \n",
            "[18] {mayo}                   0.01799760 135  \n",
            "[19] {dark}                   0.01199840  90  \n",
            "[20] {vegetables,mineral}     0.01413145 106  \n",
            "[21] {red}                    0.01639781 123  \n",
            "[22] {water,olive}            0.01253166  94  \n",
            "[23] {vegetables,ground}      0.01213172  91  \n",
            "[24] {juice}                  0.01866418 140  \n",
            "[25] {fries,frozen}           0.01373150 103  \n",
            "[26] {smoothie}               0.02173044 163  \n",
            "[27] {french}                 0.03492868 262  \n",
            "[28] {beef,spaghetti,mineral} 0.01453140 109  \n",
            "[29] {bar}                    0.02146380 161  \n",
            "[30] {whole}                  0.01999733 150  \n",
            "[31] {fresh}                  0.01906412 143  \n",
            "[32] {cream}                  0.02093054 157  \n",
            "[33] {ground}                 0.02906279 218  \n",
            "[34] {beef,mineral}           0.02079723 156  \n",
            "[35] {bread}                  0.02892948 217  \n",
            "[36] {herb}                   0.03092921 232  \n",
            "[37] {fries}                  0.06305826 473  \n",
            "[38] {grated}                 0.03906146 293  \n",
            "[39] {frozen}                 0.05399280 405  \n",
            "[40] {mineral}                0.07692308 577  \n",
            "[41] {&}                      0.04946007 371  \n",
            "[42] {yogurt}                 0.07239035 543  \n",
            "[43] {fat}                    0.07652313 574  \n",
            "[44] {tea}                    0.10705239 803  \n",
            "[45] {wheat}                  0.08598853 645  \n",
            "[46] {rice, wheat}            0.01226503  92  \n",
            "[47] {cream, sauce}           0.01026530  77  \n",
            "[48] {mineral, water}         0.01239835  93  \n",
            "[49] {green, tea}             0.01186508  89  \n",
            "[50] {french, fries}          0.01786428 134  \n",
            "[51] {wheat, whole}           0.01893081 142  \n",
            "[52] {&, herb}                0.03092921 232  \n",
            "[53] {fat, yogurt}            0.06839088 513  \n",
            "[54] {tea, wheat}             0.01173177  88  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in .local(.Object, ...): Unknown target type!\nTraceback:\n",
            "1. apriori(transactions, parameter = list(supp = 0.01, target = \"maximal itemsets\"))",
            "2. as(c(parameter, list(...)), \"APparameter\")",
            "3. asMethod(object)",
            "4. .list2object(from, to)",
            "5. do.call(\"new\", c(from, Class = to))",
            "6. new(support = 0.01, target = \"maximal itemsets\", Class = \"APparameter\")",
            "7. initialize(value, ...)",
            "8. initialize(value, ...)",
            "9. .local(.Object, ...)",
            "10. stop(\"Unknown target type!\")"
          ]
        }
      ],
      "source": [
        "\n",
        "# Appliquer l'algorithme Apriori pour trouver les itemsets fréquents\n",
        "frequent_itemsets <- apriori(transactions, parameter = list(supp = 0.01, target = \"frequent itemsets\"))\n",
        "\n",
        "# Afficher les itemsets fréquents\n",
        "inspect(frequent_itemsets)\n",
        "\n",
        "# Appliquer l'algorithme Apriori pour trouver les itemsets maximaux\n",
        "maximal_itemsets <- apriori(transactions, parameter = list(supp = 0.01, target = \"maximal itemsets\"))\n",
        "\n",
        "# Afficher les itemsets maximaux\n",
        "inspect(maximal_itemsets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interprétation des Résultats :**\n",
        "Chaque ligne dans vos résultats représente un itemset fréquent, avec le support indiqué pour chaque itemset. Par exemple, l'itemset {eggs} apparaît dans environ 1.2% de toutes les transactions (support = 0.01199840).\n",
        "Les itemsets sont variés, allant des produits individuels (comme {eggs} ou {escalope}) à des combinaisons de produits (comme {shrimp, frozen} ou {spaghetti, mineral}).\n",
        "\n",
        "**Itemsets Notables :**\n",
        "Certains itemsets comme {tea} et {wheat} apparaissent fréquemment dans les transactions, avec des supports respectifs de 0.10705239 et 0.08598853, ce qui indique leur popularité.\n",
        "Les combinaisons d'items comme {rice, wheat} et {cream, sauce} montrent des associations spécifiques entre produits. Ces associations peuvent être utiles pour des stratégies de marketing croisé ou pour la gestion des stocks.\n",
        "\n",
        "**Analyse des Supports :**\n",
        "Les supports varient considérablement, allant de 1.2% pour des items individuels à plus de 10% pour des items très courants comme {tea}.\n",
        "Des supports plus élevés suggèrent des items ou des combinaisons d'items particulièrement populaires ou fréquemment achetés ensemble."
      ],
      "metadata": {
        "id": "VrJHEEMx2i35"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91PS9my8I3wV"
      },
      "source": [
        "(c) Appliquez l’algorithme eclat dans le même but."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Y96xCPKkVg",
        "outputId": "160ada43-5424-4a81-e5b9-c9c693602672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eclat\n",
            "\n",
            "parameter specification:\n",
            " tidLists support minlen maxlen            target  ext\n",
            "    FALSE    0.01      1     10 frequent itemsets TRUE\n",
            "\n",
            "algorithmic control:\n",
            " sparse sort verbose\n",
            "      7   -2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "create itemset ... \n",
            "set transactions ...[5729 item(s), 7501 transaction(s)] done [0.01s].\n",
            "sorting and recoding items ... [45 item(s)] done [0.00s].\n",
            "creating sparse bit matrix ... [45 row(s), 7501 column(s)] done [0.00s].\n",
            "writing  ... [54 set(s)] done [0.00s].\n",
            "Creating S4 object  ... done [0.00s].\n",
            "     items                    support    count\n",
            "[1]  {rice, wheat}            0.01226503  92  \n",
            "[2]  {cream, sauce}           0.01026530  77  \n",
            "[3]  {mineral, water}         0.01239835  93  \n",
            "[4]  {green, tea}             0.01186508  89  \n",
            "[5]  {french, fries}          0.01786428 134  \n",
            "[6]  {wheat, whole}           0.01893081 142  \n",
            "[7]  {&, herb}                0.03092921 232  \n",
            "[8]  {fat, yogurt}            0.06839088 513  \n",
            "[9]  {tea, wheat}             0.01173177  88  \n",
            "[10] {wheat}                  0.08598853 645  \n",
            "[11] {tea}                    0.10705239 803  \n",
            "[12] {fat}                    0.07652313 574  \n",
            "[13] {yogurt}                 0.07239035 543  \n",
            "[14] {&}                      0.04946007 371  \n",
            "[15] {mineral}                0.07692308 577  \n",
            "[16] {frozen}                 0.05399280 405  \n",
            "[17] {grated}                 0.03906146 293  \n",
            "[18] {fries}                  0.06305826 473  \n",
            "[19] {herb}                   0.03092921 232  \n",
            "[20] {bread}                  0.02892948 217  \n",
            "[21] {beef,mineral}           0.02079723 156  \n",
            "[22] {ground}                 0.02906279 218  \n",
            "[23] {cream}                  0.02093054 157  \n",
            "[24] {fresh}                  0.01906412 143  \n",
            "[25] {whole}                  0.01999733 150  \n",
            "[26] {bar}                    0.02146380 161  \n",
            "[27] {beef,spaghetti,mineral} 0.01453140 109  \n",
            "[28] {french}                 0.03492868 262  \n",
            "[29] {smoothie}               0.02173044 163  \n",
            "[30] {fries,frozen}           0.01373150 103  \n",
            "[31] {juice}                  0.01866418 140  \n",
            "[32] {vegetables,ground}      0.01213172  91  \n",
            "[33] {water,olive}            0.01253166  94  \n",
            "[34] {red}                    0.01639781 123  \n",
            "[35] {vegetables,mineral}     0.01413145 106  \n",
            "[36] {dark}                   0.01199840  90  \n",
            "[37] {mayo}                   0.01799760 135  \n",
            "[38] {oil}                    0.02013065 151  \n",
            "[39] {green}                  0.02053060 154  \n",
            "[40] {water}                  0.02439675 183  \n",
            "[41] {drink}                  0.01799760 135  \n",
            "[42] {cheese}                 0.01773097 133  \n",
            "[43] {cake}                   0.02079723 156  \n",
            "[44] {wine}                   0.01573124 118  \n",
            "[45] {spaghetti,mineral}      0.01333156 100  \n",
            "[46] {sauce}                  0.01293161  97  \n",
            "[47] {dogs}                   0.01373150 103  \n",
            "[48] {rice}                   0.01279829  96  \n",
            "[49] {shrimp,frozen}          0.01026530  77  \n",
            "[50] {cookies}                0.02972937 223  \n",
            "[51] {energy}                 0.01133182  85  \n",
            "[52] {chocolate}              0.01359819 102  \n",
            "[53] {escalope}               0.01346487 101  \n",
            "[54] {eggs}                   0.01199840  90  \n",
            "     items                    support    count\n",
            "[1]  {wheat}                  0.08598853 645  \n",
            "[2]  {tea}                    0.10705239 803  \n",
            "[3]  {fat}                    0.07652313 574  \n",
            "[4]  {yogurt}                 0.07239035 543  \n",
            "[5]  {&}                      0.04946007 371  \n",
            "[6]  {mineral}                0.07692308 577  \n",
            "[7]  {frozen}                 0.05399280 405  \n",
            "[8]  {grated}                 0.03906146 293  \n",
            "[9]  {fries}                  0.06305826 473  \n",
            "[10] {herb}                   0.03092921 232  \n",
            "[11] {bread}                  0.02892948 217  \n",
            "[12] {beef,mineral}           0.02079723 156  \n",
            "[13] {ground}                 0.02906279 218  \n",
            "[14] {cream}                  0.02093054 157  \n",
            "[15] {fresh}                  0.01906412 143  \n",
            "[16] {whole}                  0.01999733 150  \n",
            "[17] {bar}                    0.02146380 161  \n",
            "[18] {beef,spaghetti,mineral} 0.01453140 109  \n",
            "[19] {french}                 0.03492868 262  \n",
            "[20] {smoothie}               0.02173044 163  \n",
            "[21] {fries,frozen}           0.01373150 103  \n",
            "[22] {juice}                  0.01866418 140  \n",
            "[23] {vegetables,ground}      0.01213172  91  \n",
            "[24] {water,olive}            0.01253166  94  \n",
            "[25] {red}                    0.01639781 123  \n",
            "[26] {vegetables,mineral}     0.01413145 106  \n",
            "[27] {dark}                   0.01199840  90  \n",
            "[28] {mayo}                   0.01799760 135  \n",
            "[29] {oil}                    0.02013065 151  \n",
            "[30] {green}                  0.02053060 154  \n",
            "[31] {water}                  0.02439675 183  \n",
            "[32] {drink}                  0.01799760 135  \n",
            "[33] {cheese}                 0.01773097 133  \n",
            "[34] {cake}                   0.02079723 156  \n",
            "[35] {wine}                   0.01573124 118  \n",
            "[36] {spaghetti,mineral}      0.01333156 100  \n",
            "[37] {sauce}                  0.01293161  97  \n",
            "[38] {dogs}                   0.01373150 103  \n",
            "[39] {rice}                   0.01279829  96  \n",
            "[40] {shrimp,frozen}          0.01026530  77  \n",
            "[41] {cookies}                0.02972937 223  \n",
            "[42] {energy}                 0.01133182  85  \n",
            "[43] {chocolate}              0.01359819 102  \n",
            "[44] {escalope}               0.01346487 101  \n",
            "[45] {eggs}                   0.01199840  90  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer l'algorithme Eclat pour trouver les itemsets fréquents\n",
        "frequent_itemsets_eclat <- eclat(transactions, parameter = list(supp = 0.01, maxlen = 10))\n",
        "\n",
        "# Afficher les itemsets fréquents\n",
        "inspect(frequent_itemsets_eclat)\n",
        "\n",
        "# Trouver les itemsets maximaux parmi les itemsets fréquents\n",
        "maximal_itemsets_eclat <- which(colSums(is.subset(frequent_itemsets_eclat, frequent_itemsets_eclat)) == 1)\n",
        "maximal_itemsets_eclat <- frequent_itemsets_eclat[maximal_itemsets_eclat]\n",
        "\n",
        "# Afficher les itemsets maximaux\n",
        "inspect(maximal_itemsets_eclat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interprétation des Résultats :**\n",
        "Les itemsets listés sont ceux qui apparaissent fréquemment dans votre base de données. Chaque itemset est accompagné de son support et du nombre de fois qu'il apparaît (count).\n",
        "Par exemple, l'itemset {tea} a un support de 0.10705239, signifiant qu'il apparaît dans environ 10.7% de toutes les transactions, et il apparaît 803 fois dans l'ensemble des données.\n",
        "\n",
        "**Itemsets Individuels vs. Combinés :**\n",
        "Vos résultats montrent à la fois des itemsets individuels (comme {wheat}, {tea}) et des combinaisons d'items (comme {rice, wheat}, {cream, sauce}).\n",
        "Les itemsets individuels avec des supports élevés comme {tea} et {wheat} indiquent leur popularité générale.\n",
        "Les combinaisons d'items révèlent des achats fréquemment réalisés ensemble, ce qui peut être utile pour les recommandations de vente croisée ou pour comprendre les habitudes d'achat."
      ],
      "metadata": {
        "id": "LkFs96Np3ZBI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avDAGQiSI6m6"
      },
      "source": [
        "(d) Utilisez la fonction system.time pour comparer le temps des deux\n",
        "algorithmes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GnskUZuKnu5",
        "outputId": "c7703ef7-2928-4863-8056-aacd1fd46b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "        0.1    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen target  ext\n",
            "     10  rules TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[5729 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [45 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "writing ... [19 rule(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "Time difference of 0.06727147 secs\n",
            "Eclat\n",
            "\n",
            "parameter specification:\n",
            " tidLists support minlen maxlen            target  ext\n",
            "    FALSE    0.01      1     10 frequent itemsets TRUE\n",
            "\n",
            "algorithmic control:\n",
            " sparse sort verbose\n",
            "      7   -2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "create itemset ... \n",
            "set transactions ...[5729 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [45 item(s)] done [0.00s].\n",
            "creating sparse bit matrix ... [45 row(s), 7501 column(s)] done [0.00s].\n",
            "writing  ... [54 set(s)] done [0.00s].\n",
            "Creating S4 object  ... done [0.00s].\n",
            "Time difference of 0.04491425 secs\n"
          ]
        }
      ],
      "source": [
        "# Mesurer le temps d'exécution de l'algorithme Apriori\n",
        "start_time <- Sys.time()\n",
        "rules <- apriori(transactions, parameter = list(supp = 0.01, conf = 0.1))\n",
        "end_time <- Sys.time()\n",
        "execution_time <- end_time - start_time\n",
        "\n",
        "# Afficher le temps d'exécution\n",
        "print(execution_time)\n",
        "\n",
        "# Mesurer le temps d'exécution pour Eclat\n",
        "start_time_eclat <- Sys.time()\n",
        "itemsets_eclat <- eclat(transactions, parameter = list(supp = 0.01, maxlen = 10))\n",
        "end_time_eclat <- Sys.time()\n",
        "time_eclat <- end_time_eclat - start_time_eclat\n",
        "\n",
        "# Afficher le temps d'exécution pour Eclat\n",
        "print(time_eclat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyse des Performances de l'Algorithme Apriori :**\n",
        "* Temps d'Exécution : L'algorithme Apriori a pris environ 0.067 secondes (Time difference of 0.06727147 secs) pour exécuter. Ce temps est relativement rapide, montrant une bonne efficacité pour la taille de votre ensemble de données.\n",
        "\n",
        "* Nombre de Règles Générées : Apriori a généré 19 règles d'association, ce qui indique que peu de règles répondent aux critères de support et de confiance définis (support minimum de 0.01 et confiance minimum de 0.1).\n",
        "\n",
        "* Utilité pour l'Analyse : Ces règles peuvent offrir des insights pertinents sur les relations entre différents items dans les transactions. Elles sont utiles pour comprendre les habitudes d'achat des clients.\n",
        "\n",
        "**Analyse des Performances de l'Algorithme Eclat :**\n",
        "\n",
        "* Temps d'Exécution : Eclat a pris environ 0.045 secondes (Time difference of 0.04491425 secs). Cela suggère que Eclat est légèrement plus rapide qu'Apriori pour ce jeu de données.\n",
        "\n",
        "* Nombre d'Itemsets Fréquents Générés : Eclat a généré 54 itemsets fréquents. Cela montre que plus d'associations répondent au critère de support minimum par rapport aux règles d'association générées par Apriori.\n",
        "\n",
        "* Utilité pour l'Analyse : Les itemsets fréquents identifiés par Eclat peuvent aider à comprendre quels groupes d'items sont souvent achetés ensemble, ce qui est utile pour la planification des stocks et les promotions.\n",
        "\n",
        "**Comparaison :**\n",
        "\n",
        "* Efficacité : Eclat s'est avéré légèrement plus rapide qu'Apriori dans ce cas, ce qui est cohérent avec les attentes, car Eclat est généralement plus efficace pour de grands ensembles de données.\n",
        "\n",
        "* Résultats : Alors qu'Apriori se concentre sur les règles d'association, Eclat identifie les itemsets fréquents. Les deux types de résultats sont utiles mais servent des objectifs analytiques légèrement différents.\n",
        "\n",
        "* Choix de l'Algorithme : Le choix entre Apriori et Eclat dépendra de l'objectif spécifique de votre analyse. Pour des règles d'association spécifiques, Apriori est préférable. Pour identifier rapidement des itemsets fréquents, Eclat est plus adapté.\n",
        "\n",
        "* Considérations sur les Paramètres : Les paramètres tels que le support minimum et la confiance jouent un rôle crucial dans le nombre de règles ou d'itemsets générés. Ils doivent être soigneusement ajustés en fonction des besoins de l'analyse."
      ],
      "metadata": {
        "id": "xpga4P8p4eIE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nXwT9rBI9XI"
      },
      "source": [
        "(e) Construisez une collection BigGr beaucoup plus grande de transac- tions issues de Groceries (avec sample(), par exemple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WGrupeUK1As"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dupliquer les transactions pour créer BigGr\n",
        "set.seed(123)  # Pour la reproductibilité\n",
        "biggr_transactions <- sample(transactions, size = length(transactions) * 5, replace = TRUE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbe079IiI_gZ"
      },
      "source": [
        "(f) Appliquez à nouveau apriori et eclat pour les itemsets fréquents et fermés (\"closed frequent itemset\") et comparez à nouveau les temps de calcul."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsOTa4anJDAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9262e10b-ca5e-445a-f9d1-0cdff5de379e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "         NA    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen            target  ext\n",
            "     10 frequent itemsets TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 375 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[5694 item(s), 37505 transaction(s)] done [0.05s].\n",
            "sorting and recoding items ... [46 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.01s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "sorting transactions ... done [0.01s].\n",
            "writing ... [54 set(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "[1] \"Temps d'exécution pour Apriori sur BigGr: 0.0947248935699463\"\n",
            "Eclat\n",
            "\n",
            "parameter specification:\n",
            " tidLists support minlen maxlen            target  ext\n",
            "    FALSE    0.01      1     10 frequent itemsets TRUE\n",
            "\n",
            "algorithmic control:\n",
            " sparse sort verbose\n",
            "      7   -2    TRUE\n",
            "\n",
            "Absolute minimum support count: 375 \n",
            "\n",
            "create itemset ... \n",
            "set transactions ...[5694 item(s), 37505 transaction(s)] done [0.06s].\n",
            "sorting and recoding items ... [46 item(s)] done [0.00s].\n",
            "creating sparse bit matrix ... [46 row(s), 37505 column(s)] done [0.00s].\n",
            "writing  ... [54 set(s)] done [0.01s].\n",
            "Creating S4 object  ... done [0.00s].\n",
            "[1] \"Temps d'exécution pour Eclat sur BigGr: 0.0938329696655273\"\n"
          ]
        }
      ],
      "source": [
        "# Appliquer Apriori pour les itemsets fréquents sur BigGr\n",
        "start_time_apriori_biggr <- Sys.time()\n",
        "frequent_itemsets_apriori_biggr <- apriori(biggr_transactions, parameter = list(supp = 0.01, target = \"frequent itemsets\"))\n",
        "end_time_apriori_biggr <- Sys.time()\n",
        "time_apriori_biggr <- end_time_apriori_biggr - start_time_apriori_biggr\n",
        "\n",
        "# Afficher le temps d'exécution pour Apriori sur BigGr\n",
        "print(paste(\"Temps d'exécution pour Apriori sur BigGr:\", time_apriori_biggr))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Appliquer Eclat pour les itemsets fréquents sur BigGr\n",
        "start_time_eclat_biggr <- Sys.time()\n",
        "frequent_itemsets_eclat_biggr <- eclat(biggr_transactions, parameter = list(supp = 0.01, maxlen = 10))\n",
        "end_time_eclat_biggr <- Sys.time()\n",
        "time_eclat_biggr <- end_time_eclat_biggr - start_time_eclat_biggr\n",
        "\n",
        "# Afficher le temps d'exécution pour Eclat sur BigGr\n",
        "print(paste(\"Temps d'exécution pour Eclat sur BigGr:\", time_eclat_biggr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyse de l'Algorithme Apriori sur BigGr :**\n",
        "\n",
        "* Paramètres de l'Algorithme : Le support minimum est fixé à 0.01, et l'objectif est de trouver des itemsets fréquents. La taille maximale des itemsets est de 10.\n",
        "\n",
        "* Nombre d'Itemsets Fréquents Générés : Apriori a identifié 54 itemsets fréquents dans une collection de 37,505 transactions, ce qui indique une bonne identification des patterns fréquents dans un ensemble de données plus grand.\n",
        "\n",
        "* Temps d'Exécution : Le temps d'exécution pour Apriori sur BigGr est d'environ 0.095 secondes. Cette performance montre que l'algorithme gère bien l'augmentation de la taille des données.\n",
        "\n",
        "**Analyse de l'Algorithme Eclat sur BigGr :**\n",
        "* Paramètres de l'Algorithme : Eclat a également été exécuté avec un support minimum de 0.01 pour identifier les itemsets fréquents.\n",
        "\n",
        "* Nombre d'Itemsets Fréquents Générés : Eclat a également généré 54 itemsets fréquents, ce qui est cohérent avec les résultats d'Apriori.\n",
        "\n",
        "* Temps d'Exécution : Le temps d'exécution pour Eclat sur BigGr est d'environ 0.094 secondes, légèrement plus rapide que Apriori, mais la différence est minime.\n",
        "\n",
        "**Comparaison et Conclusion :**\n",
        "\n",
        "* Performance des Deux Algorithmes : Les deux algorithmes ont montré une efficacité similaire en termes de temps d'exécution sur un grand ensemble de données, avec Eclat légèrement plus rapide que Apriori.\n",
        "\n",
        "* Cohérence des Résultats : Le fait que les deux algorithmes aient identifié le même nombre d'itemsets fréquents renforce la fiabilité des résultats.\n",
        "\n",
        "* Implications pour le TP : Ces résultats démontrent que les deux algorithmes sont bien adaptés pour traiter des ensembles de données volumineux, et ils fournissent des insights précieux sur les tendances d'achat dans un ensemble de données étendu."
      ],
      "metadata": {
        "id": "Zk629aDX8f0_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bc-JV7EJDUu"
      },
      "source": [
        "##**2. (optionnel) Réalisez sur la grande collection BigGr une implémentation de Partition-apriori**.\n",
        "\n",
        "Il y a la fonction duplicated qui détecte des \"éléments\" (itemsets, tran- sactions ou règles d’association) redondants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiOhMlWaXMrs",
        "outputId": "ffa61112-1cce-4967-d585-05f1f23bac61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "         NA    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen            target  ext\n",
            "     10 frequent itemsets TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[4128 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [47 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "sorting transactions ... done [0.00s].\n",
            "writing ... [55 set(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "         NA    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen            target  ext\n",
            "     10 frequent itemsets TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[4054 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [45 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "sorting transactions ... done [0.00s].\n",
            "writing ... [53 set(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "         NA    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen            target  ext\n",
            "     10 frequent itemsets TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[4090 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [46 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "sorting transactions ... done [0.00s].\n",
            "writing ... [54 set(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "         NA    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen            target  ext\n",
            "     10 frequent itemsets TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[3961 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [47 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "sorting transactions ... done [0.00s].\n",
            "writing ... [56 set(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n",
            "Apriori\n",
            "\n",
            "Parameter specification:\n",
            " confidence minval smax arem  aval originalSupport maxtime support minlen\n",
            "         NA    0.1    1 none FALSE            TRUE       5    0.01      1\n",
            " maxlen            target  ext\n",
            "     10 frequent itemsets TRUE\n",
            "\n",
            "Algorithmic control:\n",
            " filter tree heap memopt load sort verbose\n",
            "    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n",
            "\n",
            "Absolute minimum support count: 75 \n",
            "\n",
            "set item appearances ...[0 item(s)] done [0.00s].\n",
            "set transactions ...[4086 item(s), 7501 transaction(s)] done [0.02s].\n",
            "sorting and recoding items ... [42 item(s)] done [0.00s].\n",
            "creating transaction tree ... done [0.00s].\n",
            "checking subsets of size 1 2 done [0.00s].\n",
            "sorting transactions ... done [0.00s].\n",
            "writing ... [48 set(s)] done [0.00s].\n",
            "creating S4 object  ... done [0.00s].\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Diviser les transactions en partitions (par exemple, en 5 partitions)\n",
        "partition_size <- length(biggr_transactions) / 5\n",
        "partitions <- split(biggr_transactions, ceiling(seq_along(biggr_transactions) / partition_size))\n",
        "\n",
        "# Fonction pour appliquer Apriori à une partition\n",
        "apply_apriori <- function(partition, min_support = 0.01) {\n",
        "    return(apriori(partition, parameter = list(supp = min_support, target = \"frequent itemsets\")))\n",
        "}\n",
        "\n",
        "# Appliquer Apriori à chaque partition et stocker les résultats\n",
        "results <- lapply(partitions, apply_apriori)\n",
        "\n",
        "\n",
        "# Fonction pour trouver les itemsets communs\n",
        "find_common_itemsets <- function(results) {\n",
        "    common_itemsets <- results[[1]]\n",
        "    for (result in results[-1]) {\n",
        "        common_itemsets <- intersect(common_itemsets, result)\n",
        "    }\n",
        "    return(common_itemsets)\n",
        "}\n",
        "\n",
        "# Trouver les itemsets communs\n",
        "common_itemsets <- find_common_itemsets(results)\n",
        "\n",
        "# Éliminer les itemsets redondants\n",
        "unique_itemsets <- unique(common_itemsets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIH7RO0tMBUM"
      },
      "source": [
        "**Analyse des Résultats de Partition-Apriori :**\n",
        "\n",
        " **Nombre d'Itemsets Fréquents Identifiés :**\n",
        " * Chaque exécution de l'algorithme Apriori sur les différentes partitions a identifié un nombre variable d'itemsets fréquents, allant de 48 à 56 itemsets.\n",
        "\n",
        "* Cette variation indique que différents segments de votre ensemble de données (représentés par chaque partition) possèdent des caractéristiques et des associations d'items uniques.\n",
        "\n",
        "**Variabilité des Itemsets :**\n",
        "* Le nombre d'items uniques dans chaque partition varie, allant de 3961 à 4128, ce qui peut influencer le nombre d'itemsets fréquents identifiés.\n",
        "\n",
        "* Cette variation souligne l'importance de la diversité des transactions au sein de chaque partition et son impact sur l'identification des patterns fréquents.\n",
        "\n",
        "\n",
        "**Implications pour l'Analyse de Données :**\n",
        "* Ces résultats montrent que l'utilisation de l'algorithme Partition-Apriori permet de capturer des nuances dans les associations d'items qui pourraient être manquées en analysant l'ensemble des données en bloc.\n",
        "\n",
        "* Les différences observées entre les partitions pourraient fournir des insights sur les variations de comportement d'achat ou des préférences au sein de sous-groupes de votre base de clients.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##**Conclusion**\n",
        "L'approche Partition-Apriori révèle des informations détaillées et spécifiques à certaines parties de l'ensemble des données, ce qui peut être particulièrement utile pour une analyse ciblée ou segmentée.\n",
        "\n",
        "Les variations dans les itemsets fréquents identifiés soulignent l'importance de considérer la diversité des transactions lors de l'analyse des habitudes d'achat.\n",
        "\n",
        "Ces résultats pourraient être utilisés pour formuler des recommandations spécifiques à certaines catégories de produits ou pour améliorer les stratégies de marketing ciblé."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}